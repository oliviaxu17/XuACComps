---
output: 
  pdf_document: 
    latex_engine: xelatex
---
<!--
The {#rmd-basics} text after the chapter declaration will allow us to link throughout the document back to the beginning of Chapter 1.  These labels will automatically be generated (if not specified) by changing the spaces to hyphens and capital letters to lowercase.  Look for the reference to this label at the beginning of Chapter 2.
-->

# Twain Basics: \textit{The Adventures of Tom Sawyer} {#rmd-basics}

```{r, include = FALSE}
# packages needed
library(mosaic) 
library(XML)
library(readr)
library(devtools)
library(stringr)
library(RCurl)
library(syuzhet)
library(tm)
```

```{r, include = FALSE}
tomsawyerURL <- "http://www.gutenberg.org/files/74/74-0.txt"
tomsawyertext <- scan(tomsawyerURL, what = "character", sep = "\n")
```

As I stated in the **Introduction**, due to Twain having such a large and extensive body of work, it was necessary to pick and choose works that I wanted to use for my analysis.  A quick google search easily told me some of his most famous works, and so I tried to pick novels that he was famous for, while also making sure I had a selection from each phase of his writing career (early, middle, and end).  The works that ended up meeting those criteria are listed below.

1. \textit{Innocents Abroad} (early - 1869)
2. \textit{Roughing It} (early - 1872)
3. \textit{The Adventures of Tom Sawyer} (middle - 1876)
4. \textit{The Adventures of Huckleberry Finn} (middle - 1884)
5. \textit{A Connecticut Yankee in King Arthur's Court} (late - 1889)
6. \textit{Pudd'nhead Wilson} (late - 1894)

These texts are all available online for free at the Project Gutenberg website <http://www.gutenberg.org/>.  After extracting and cleaning the text from the website, (for a more detailed process, please see my _TwainWrangle.Rmd_ file in GitHub) we are ready for some text analysis.

### Goals and Objections 
Using the works of Mark Twain, I hope to capture the essence of his writings using stylometric and sentiment markers.  I will then also use his works to introduce a different type of text analysis, the Latent Dirichlet Allocation method.

### Case Study: \textit{The Adventures of Tom Sawyer}

Like we did with our Mansfield project, let's first start off by looking at one novel before looking at them all together.  

#### About: Tom Sawyer
A story that is familiar to most people, \textit{The Adventures of Tom Sawyer} was Twain's "Great American novel".  The book starts off with young Tom Sawyer whitewashing a fence as punishment.  Tom is a mischievous little boy, and with his friend Huckleberry Finn, the two witness a murder at a graveyard.  Scared that the murderer will come after them next, they escape to an island.  Out of remorse, the two return home and help solve the murder mystery.

#### Sentiment Analysis
I will be using the `syuzhet` package in R to perform sentiment analysis (see the Mansfield project for more information and reasons why we chose syuzhet).  The graph we get of the sentiment with the Fourier transform applied is exactly what we expect.  The story starts off positive and ends positively.  The highs and lows of the graph also match up nicely with key plot points; for example, we see an increase in positive sentiment when Tom meets these two pretty girls, but then the novel becomes much darker after the boys witness the murder of the doctor.        

```{r, include = FALSE}
# cleaning tom sawyer text
findstart <- function(text){ 
  startend <- 0
  for (i in 1:length(text)){
    if (text[i] == "CHAPTER I") {
      startend <- i
    }
  }
  for (j in 50:length(text)){
    if (text[j] == "CONCLUSION") {
      startend <- c(startend, j)
      return(startend)
    }
  }
} 

actualtext <- function(text, startend){
  realtext <- text[startend[1]:startend[2]]
  return (realtext)
}

# tom sawyer text
tomsawyerstartend <- findstart(tomsawyertext)
tomsawyertext <- actualtext(tomsawyertext, tomsawyerstartend)
tomsawyertext <- iconv(tomsawyertext,"WINDOWS-1252","UTF-8")
```

```{r, include=FALSE}
#sentiment data
tomsent <- get_sentiment(tomsawyertext, "syuzhet")
tomsenttrans <- as.numeric(get_transformed_values(tomsent, 
                                  low_pass_size = 3,
                                  scale_vals = TRUE,
                                  scale_range = FALSE))
tomsentdata <- data.frame(cbind(linenumber = seq_along(tomsenttrans), ft = tomsenttrans))
```

```{r, echo=FALSE, cache=TRUE, warning = FALSE, fig.align="center"}
# tom sawyer sentiment graph with Fourier transform
ggplot(data = tomsentdata, aes(x = linenumber, y = ft)) +
        geom_bar(stat = "identity", alpha = 0.8, color = "midnightblue", fill = "midnightblue") +
        theme_minimal() +
        ylab("Transformed Sentiment Value") +
        ggtitle(expression(paste("Sentiment in ", italic("The Adventures of Tom Sawyer")))) +
        theme(axis.title.x=element_blank()) +
        theme(axis.ticks.x=element_blank()) +
        theme(axis.text.x=element_blank()) +
ggplot2::annotate("text", size = 3, x = c(8, 18, 22, 38, 71, 85), 
                 y = c(2.3, -1.3, 1.5, .9, 1.1, -1.1), 
                 label = c("Meets Amy Lawrence", "Falls in love\n with Becky",
                           "Witness graveyard\n murder", "Escape to island",
                           "Trial of Potter and Injun Joe", "Huck saves widow")) +
        ggplot2::annotate("segment", arrow = arrow(length = unit(0.03, "npc")),
                 x = c(8, 18, 22, 38, 71, 87), xend = c(8, 18, 22, 38, 71, 87),
                 y = c(2.2, -1, 1.2, .8, 1, -1), 
                 yend = c(1.7, -.1 , 0.3, .1, .3, -.2))
```


#### Stylometric Analysis
Using the `katherinemansfieldr` package that Andrew and I built last semester, I will be applying the functions we put in that package to measure certain stylometric markers in Tom Sawyer.  Below are two graphs depicting the sentence length over time in the book and token length over time.  As we can see, while the graphs are interesting to look at, there doesn't seem to be a clear cut pattern in sentence or token length throughout the book.  However, the two graphs do seem to loosely follow the Fourier sentiment graph from above; longer sentences and tokens seem to be related to the more positive portions of the novel.      

```{r, include = FALSE}
devtools::install_github("Amherst-Statistics/katherinemansfieldr")
library(katherinemansfieldr)
```

```{r, include = FALSE}
# sentence length in Tom Sawyer
sentlen <- function(sentences) {
  senlen <- 0
  for (i in 1:length(sentences)) {
    sentlen <- sapply(gregexpr("\\W+", sentences[i]), length) + 1
    senlen <- c(senlen, sentlen)
  }
  senlen <- senlen[-1]
  return(senlen)
}

tomSentences <- extract_sentences(tomsawyertext)
tomsenlen <- sentlen(tomSentences)
```

```{r, echo = FALSE, cache=TRUE, fig.align="center", fig.height=3, fig.width=4}
data <- as.data.frame(cbind(tomsenlen, c(1:length(tomsenlen))))
ggplot(data, aes(x = V2, y = tomsenlen)) + geom_smooth() + 
  geom_hline(yintercept = mean(data$tomsenlen), color = "red", linetype = "dashed") + ylab("Sentence Length") + xlab("Sentence number") + ggtitle("Sentence Length across Tom Sawyer")
```

```{r, include = FALSE}
# token length tom sawyer
tomToken <- extract_token(tomsawyertext)

tokenlen <- function(token) {
  toklen <- 0
  for (i in 1:length(token)) {
    tokenlen <- nchar(token[i])
    toklen <- c(toklen, tokenlen)
  }
  toklen <- toklen[-1]
  return(toklen)
}

tokenlength <- tokenlen(tomToken)
```

```{r, echo = FALSE, cache = TRUE, fig.align="center", fig.height=3, fig.width=4}
data <- as.data.frame(cbind(tokenlength, c(1:length(tokenlength))))
ggplot(data, aes(x = V2, y = tokenlength)) + geom_smooth() + 
  geom_hline(yintercept = mean(data$tokenlength), color = "red", linetype = "dashed") + ylab("Token Length") + xlab("Token number") + ggtitle("Token Length across Tom Sawyer")
```

